\section{threading: Einblick}

\subsection{Konzeptuelles}

\begin{frame}{Historisches}
	\begin{block}{Hardware}
		Historische Architektur: Berechnungen auf CPU mit einem oder wenigen Kernen \\
		$\implies$ sequentielles Programmieren, sequentielle Prozeduren
		
		\vspace{1em}
		
		langsame Steigerung der Zahl Kerne \\
		$\implies$ unabhängige, parallel ausgeführte Programmsequenzen
	\end{block}
	
	\pause
	\vspace{1em}
	
	\begin{block}{Software}
		Mehrere Aufgaben (Tasks) gleichzeitig \\
		$\implies$ multi-tasking
		
		\vspace{1em}
		
		unabhängige Tasks \\
		$\implies$ Support durch OS
	\end{block}
\end{frame}

\begin{frame}{Was ist ein Thread?}
	\begin{block}{Sequentielles Programmieren}
		\begin{itemize}
			\item Programm besteht aus Reihe von Befehlssequenzen
			\item Befehle einer Sequenz werden strikt nacheinander ausgeführt
		\end{itemize}
	\end{block}
	
	\pause
	
	\begin{block}{Thread}
		\begin{itemize}
			\item Ein Thread fürt vorgegebene Abfolge von Sequenzen aus	\\
				$\implies$ Befehlsfluss
			\item Mehrere Threads bearbeiten unabhängige Abfolgen
				$\implies$ mehrere \enquote{parallele} Flüsse
			\item Threads teilen sich bestimmte Dinge \dots
			\item \dots haben aber auch individuelle Zuordnungen
			\item bisher: ein Thread, der die \texttt{main} ausführt
			\item jetzt: \emph{zusätzlich} beliebige Zahl Threads
		\end{itemize}
	\end{block}
\end{frame}

\begin{frame}{threads in sequentiellem Programmieren (1)}
	\begin{block}{thread scheduling}
		\begin{enumerate}
			\item Ein Thread durchläuft das Programm (Ausführung).
			\item Der Programmablauf wird zu einem unbekannten Zeitpunkt unterbrochen.
			\item Andere Threads werden fortgesetzt.
			\item Irgendwann wird der eigene Thread fortgesetzt.
		\end{enumerate}
		
		\pause
		
		\begin{itemize}
			\item Keine Garantie, wann unterbrochen wird.
			\item Keine Garantie, wer wann ausgeführt/fortgesetzt wird.
			\item Mehrere Threads: weiß nicht ohne Stoppen, wer wann wo ist. (Unschärferelation!)
			\item Fortsetzen \enquote{als wäre nichts geschehen} (wie standby)
		\end{itemize}
	\end{block}
\end{frame}

\begin{frame}{threads in sequentiellem Programmieren (2)}
	\begin{block}{concurrent threads}
		Bei mehreren Kernen/CPUs/\dots: gleichzeitiges Ausführen mehrerer Threads möglich.
		Dieselben (nicht-)Garantien wie bei thread scheduling!
	\end{block}
	
	Resultat: Kenne den Zustand eines anderen Threads \emph{nur bei Synchronisierung}!\\
	Analogie: Unbestimmtheit eines Teilchenzustandes bis zur Messung
	
	\pause
	\vspace{1em}
	
	\begin{block}{Kombiniert}
		\begin{itemize}
			\item thread != Kern (außer mit Aufwand)
			\item OS verwaltet Zuweisung thread $\leftrightarrow$ Kern
			\item Viele Threads möglich, u.U. sinnvoll wenn diese oft schlafen
		\end{itemize}
	\end{block}
\end{frame}

\begin{frame}{Grundlegende Probleme}
	Bei sequentiellem Programm-Design!
	
	\vspace{0.5em}
	
	Kein Problem: Mehrere unabhängige Sequenzen\\
	Probleme bei \emph{Interaktion} und \emph{Überlappungen}
	\begin{itemize}
		\item Schreibzugriff auf Daten
		\item Synchronisierung (z.B. Warten)
		\item Übergeben von Daten
		\item Exceptions (!)
	\end{itemize}
	
	\vspace{0.5em}
	
	Zusätzlicher Aspekt (neben const correctness, exception safety usw.):
	\begin{block}{threading safety}
		\textbf{Heißt:} Was darf ich von welchem thread aus mit einer Funktion / einer Instanz tun?
	\end{block}
	
	\pause
	
	\alert{Viele der Probleme können durch ein besseres Design schon vermieden werden, z.B. message-based, event-driven, callbacks usw.}
\end{frame}


\subsection{threads in sequentiellem C++11}

\begin{frame}[fragile]{threads und storage duration}
	\footnotesize
	\vspace{-0.5em}
	
	\begin{block}{\footnotesize Zugriff auf ein »Ding« über seinen Namen}
		\begin{itemize}
			\item Jeder thread hat seinen eigenen Stack
			\item automatic storage: unabhängig
			\item static storage: geteilt
			\item dynamic storage: n/A (kein Name!)
			\item thread-local storage: duration wie bei static, aber Daten individuell pro thread
		\end{itemize}
	\end{block}
	\alert<1>{Zugriff über Pointer immer möglich!}
	
	\pause
	
	\begin{lstlisting}[basicstyle=\scriptsize]
		int stS = 42;
		thread_local bool tlS;
		
		void foo(int* ptr) {
		    int auS = 5;
		    stS = 15;
		    tlS = 10;
			
		    *ptr = 21;
		    double* dyS2 = new double(3.0);
		}
	\end{lstlisting}
\end{frame}

\begin{frame}{threads in sequentiellem C++11}
	\begin{itemize}
		\item Vor C++11: diverse threading-Bibliotheken, z.B. pthreads oder boost
		\item Mit C++11: größte \emph{gemeinsame} Basis im Standard selbst (reicht für alles Grundlegende)
		\item externe Bibliotheken nicht obsolet für Spezialanwendungen \dots
		\item \dots aber besser zu vermeiden
	\end{itemize}
	
	\pause
	
	\begin{block}{std::thread}
		Die Thread-Klasse in C++11
		\begin{itemize}
			\item RAII: Erzeugung einer Instanz = Starten eines Threads (außer default-ctor)
			\item Übergabe einer Funktion wie bei \texttt{std::bind}
			\item member functions \texttt{join}, \texttt{joinable}, \texttt{detach}
			\item Achtung: dtor terminiert das Programm, wenn der thread noch läuft!
			\item static member function: \texttt{hardware\_concurrency}
		\end{itemize}
	\end{block}
\end{frame}

\begin{frame}[fragile]{Beispiel: \texttt{std::thread}}
	\begin{columns}[b]
		\column{0.4\textwidth}
			\begin{lstlisting}
				void calc(int,
				          int& result);
				
				
				
				#include <thread>
				
				int result = 0;
				std::thread myThread =
				    {&calc, 5, 
				     std::ref(result)};
					 
				/* do something else */
				
				myThread.join();
				
				std::cout << result;
			\end{lstlisting}
		
		\pause
		
		\column{0.6\textwidth}
			\begin{lstlisting}
				struct Calculator {
				    void calc(int);
				    int result;
				};
				
				
				#include <thread>
				
				Calculator myCalc;
				std::thread myThread =
				    {&MyCalculator::calc, 
				     std::ref(myCalc), 5};
				
				/* do something else */
				
				myThread.join();
				
				std::cout << myCalc.result;
			\end{lstlisting}
	\end{columns}
\end{frame}

\begin{frame}{concurrent data access}
	\begin{itemize}
		\item Reines Lesen von (konstanten) Daten ist meist kein Problem.
		\item Gibt es einen Schreibenden $\implies$ Probleme
		\item Einfachste Lösung: locking
		\item Hinweis: Auf Puffern durch Compiler achten (\texttt{volatile})
	\end{itemize}
	
	\pause
	
	\begin{block}{Mutex: Konzeptuell}
		\begin{itemize}
			\item Einfachste Form des lockings
			\item Amortisiert so ziemlich das langsamste locking (da sehr allgemein)
			\item Mutex = Mutual exclusion
			\item Es kann zu jedem Zeitpunkt maximal ein Thread das Mutex \enquote{besitzen} (sperren)
			\item Andere Threads können auf das Mutex warten und einer der wartenden erhält dann den Besitz
		\end{itemize}
	\end{block}
\end{frame}

\begin{frame}{ \texttt{std::mutex} }
	\begin{block}{std::mutex}
		Wichtigste member functions:
		\begin{itemize}
			\item \texttt{lock} -- lässt den aktuellen Thread auf den Besitz dieses Mutexes warten
			\item \texttt{try\_lock} -- versucht, den Besitz sofort zu erhalten (falls kein aktueller Besitzer)
			\item \texttt{unlock}
		\end{itemize}
	\end{block}
	
	\pause
	
	\alert{Häufiges Problem: \texttt{unlock} vergessen}
	\begin{block}{std locks}
		\begin{itemize}
			\item RAII: Wie smart ptr, nur eben für locking
			\item Im ctor \texttt{lock}, im dtor \texttt{unlock}
			\item Wichtigster Vertreter: \texttt{std::unique\_lock}
		\end{itemize}
	\end{block}
\end{frame}

\begin{frame}[fragile]{ Beispiel: \texttt{mutex} + \texttt{unique\_lock} }
	\begin{lstlisting}
		#include <mutex>
		shared_ptr < LargeData >   pDat;
		shared_ptr < std::mutex >  pDat_mutex;
		
		void calc(int p)
		{
		    shared_ptr < LargeData >  pDat_my       = pDat;
		    shared_ptr < std::mutex > pDat_mutex_my = pDat_mutex;
			
		    /* ... */
			
		    { unique_lock datLock = {*pDat_mutex_my};
		        pDat_my->change();
		    }
			
		    /* ... */
		}
	\end{lstlisting}
\end{frame}

\begin{frame}[fragile]{dead-lock}
	\footnotesize
	\alert{Wechselseitiges Blockieren $\implies$ unendliches Warten}
	
	\begin{lstlisting}[basicstyle=\scriptsize]
		shared_ptr < AdditionalData >  pAddDat;
		shared_ptr < std::mutex >      pAddDat_mutex;
		
		void calc0(int p) {
		    shared_ptr < AdditionalData > pAddDat_my       = pDat;
		    shared_ptr < std::mutex >     pAddDat_mutex_my = ppAddDat_mutex;
		    /* ... */
		    {unique_lock addDatLock = {*pAddDat_mutex_my};
		     unique_lock    datLock = {*pDat_mutex_my};
		        pDat_my->change();
		    }
		}
		void calc1(int p) {
		    shared_ptr < AdditionalData > pAddDat_my       = pDat;
		    shared_ptr < std::mutex >     pAddDat_mutex_my = ppAddDat_mutex;
		    /* ... */
		    {unique_lock    datLock = {*pDat_mutex_my};
		     unique_lock addDatLock = {*pAddDat_mutex_my};
		        pMyDat_my->change();
		    }
		}
	\end{lstlisting}
\end{frame}


\subsection{Einstieg in elegantere concurrency}

\begin{frame}{Einstieg in elegantere concurrency: \texttt{async}}
	Ein Traum wie aus einer Script-Sprache:
	\begin{block}{ \texttt{std::async} }
		\begin{itemize}
			\item \texttt{async} ist eine Funktion, Parameter wie beim ctor von \texttt{thread}
			\item führ die angegebene Funktion aus, wobei die Implementierung/OS entscheidet, ob \emph{sofort} in einem neuen Thread oder \emph{später} (lazy evaluation)
			\item kann gezwungen werden per Parameter, einen neuen Thread zu starten oder auch nicht (lazy evaluation)
			\item Rückgabetyp: ein \texttt{future}
		\end{itemize}
	\end{block}
\end{frame}

\begin{frame}{Einstieg in elegantere concurrency: promises \& futures}
	Hier nur als Skizze!
	
	\begin{block}{promises \& futures}
		aktueller Thread = $A$, (neuer) Thread für Aufgabe = $N$
		\begin{itemize}
			\item $A$ erwartet ein Resultat in einer gewissen Form (Typ): \texttt{future}
			\item $N$ verspricht, das Resultat zu geben, und zwar an einen bestimmten \enquote{Ort}: \texttt{promise}
			\item<2-> $A$ kann mittels der \texttt{future} auf $N$ warten und dann den Rückgabewert auslesen
			\item<2-> ODER, bei lazy evaluation: $A$ berechnet selbst das Ergebnis, aber erst wenn es angefordert wird
			\item<3-> Beim Auslesen dieses Rückgabewertes kann eine Exception von $N$ nach $A$ propagiert werden!
		\end{itemize}
	\end{block}
\end{frame}

\begin{frame}[fragile]{ Beispiel: \texttt{async} \& \texttt{future} }
	\begin{lstlisting}
		int calcHard(int i, double d)
		{
		    int result;
		    /* work hard, maybe throw up */
		    return result;
		}
		
		
		#include <future>
		
		future < int > future_result = async(&calcHard, 42, 21.0);
		/* do something or not */
		int result = future_result.get();
	\end{lstlisting}
\end{frame}
