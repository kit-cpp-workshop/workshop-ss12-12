\section{threading: Einblick}

\subsection{Konzeptuelles}

\begin{frame}{threads}
	\begin{block}{Hardware}
		Historische Architektur: Berechnungen auf CPU mit einem oder wenigen Kernen \\
		$\implies$ sequentielles Programmieren, sequentielle Prozeduren
		
		\vspace{1em}
		
		langsame Steigerung der Zahl Kerne \\
		$\implies$ unabhängige, parallel ausgeführte Programmsequenzen
	\end{block}
	
	\pause
	\vspace{1em}
	
	\begin{block}{Software}
		Mehrere Aufgaben (Tasks) gleichzeitig \\
		$\implies$ multi-tasking
		
		\vspace{1em}
		
		unabhängige Tasks \\
		$\implies$ Support durch OS
	\end{block}
\end{frame}

\begin{frame}{threads in sequentiellem Programmieren (1)}
	\begin{block}{Multi-Tasking}
		\begin{enumerate}
			\item Der Task / das Programm läuft.
			\item Der Programmablauf wird zu einem unbekannten Zeitpunkt unterbrochen.
			\item Andere Tasks werden fortgesetzt.
			\item Irgendwann wird der eigene Task fortgesetzt.
		\end{enumerate}
		
		\pause
		
		\begin{itemize}
			\item Keine Garantie, wann unterbrochen wird.
			\item Keine Garantie, wer wann ausgeführt/fortgesetzt wird.
			\item Mehrere Tasks: weiß nicht ohne Stoppen, wer wann wo ist (Unschärferelation!).
			\item Fortsetzen \enquote{als wäre nichts geschehen} (wie standby)
		\end{itemize}
	\end{block}
\end{frame}

\begin{frame}{threads in sequentiellem Programmieren (2)}
	\begin{block}{Multi-Threading}
		Dieselben Garantien, konzeptuell aber mglw. \emph{parallele Ausführung}.
	\end{block}
	
	\pause
	\vspace{2em}
	
	\begin{block}{Kombiniert}
		\begin{itemize}
			\item thread != Kern (außer mit Aufwand)
			\item OS verwaltet Zuweisung thread-Kern
			\item Viele Threads möglich, u.U. sinnvoll wenn diese oft schlafen
		\end{itemize}
	\end{block}
\end{frame}

\begin{frame}{Grundlegende Probleme}
	Bei sequentiellem Programm-Design!
	
	\vspace{1em}
	
	Kein Problem: Mehrere unabhängige Sequenzen\\
	Probleme bei \emph{Interaktion} und \emph{Überlappungen}
	\begin{itemize}
		\item Schreibzugriff auf Daten
		\item Synchronisierung (z.B. Warten)
		\item Übergeben von Daten
		\item Exceptions (!)
	\end{itemize}
	
	\vspace{1em}
	
	Zusätzlicher Aspekt (neben const correctness, exception safety usw.):
	\begin{block}{threading safety}
		\textbf{Heißt:} Was darf ich von welchem thread aus mit einer Funktion / einer Instanz tun?
	\end{block}
	
	\pause
	
	\alert{Viele der Probleme können durch ein besseres Design schon vermieden werden, z.B. message-based, event-driven, callbacks usw.}
\end{frame}


\subsection{threads in sequentiellem C++11}

\begin{frame}{threads und storage duration}
\end{frame}

\begin{frame}{threads in sequentiellem C++11}
	\begin{itemize}
		\item Vor C++11: diverse threading-Bibliotheken, z.B. pthreads oder boost
		\item Mit C++11: größte \emph{gemeinsame} Basis im Standard selbst (reicht für alles Grundlegende)
		\item externe Bibliotheken nicht obsolet für Spezialanwendungen \dots
		\item \dots aber besser zu vermeiden
	\end{itemize}
	
	\pause
	
	\begin{block}{std::thread}
		Die Thread-Klasse in C++11
		\begin{itemize}
			\item RAII: Erzeugung einer Instanz = Starten eines Threads (außer default-ctor)
			\item Übergabe einer Funktion wie bei \texttt{std::bind}
			\item member functions \texttt{join}, \texttt{joinable}, \texttt{detach}
			\item Achtung: dtor terminiert das Programm, wenn der thread noch läuft!
			\item static mem function: \texttt{hardware\_concurrency}
		\end{itemize}
	\end{block}
\end{frame}

\begin{frame}[fragile]{Beispiel: \texttt{std::thread}}
	\begin{columns}[b]
		\column{0.4\textwidth}
			\begin{lstlisting}
				void calc(int,
				          int& result);
				
				
				
				#include <thread>
				
				int result = 0;
				std::thread myThread =
					{&calc,
					 5, std::ref(result)};
					 
				/* do something else */
				myThread.join();
				
				std::cout << result;
			\end{lstlisting}
		
		\pause
		
		\column{0.6\textwidth}
			\begin{lstlisting}
				struct Calculator {
					void calc(int);
					int result;
				};
				
				
				#include <thread>
				
				Calculator myCalc;
				std::thread myThread =
					{&MyCalculator::calc, std::ref(myCalc),
					 5};
				
				/* do something else */
				myThread.join();
				
				std::cout << myCalc.result;
			\end{lstlisting}
	\end{columns}
\end{frame}

\begin{frame}{concurrent data access}
	\begin{itemize}
		\item Reines Lesen von Daten ist meist kein Problem.
		\item Einfachste Lösung für Schreibzugriff: locking
		\item Hinweis: auf Puffern durch Compiler achten (\texttt{volatile})
	\end{itemize}
	
	\pause
	
	\begin{block}{Mutex: Konzeptuell}
		\begin{itemize}
			\item Einfachste Form des lockings
			\item Amortisiert so ziemlich das langsamste locking (da sehr allgemein)
			\item Mutex = Mutual exclusion
			\item Es kann zu jedem Zeitpunkt maximal ein Thread das Mutex \enquote{besitzen} (sperren)
			\item Andere Threads können auf das Mutex warten und einer der wartenden erhält dann den Besitz
		\end{itemize}
	\end{block}
\end{frame}

\begin{frame}{ \texttt{std::mutex} }
	\begin{block}{std::mutex}
		Wichtigste member functions:
		\begin{itemize}
			\item \texttt{lock} -- lässt den aktuellen Thread auf den Besitz dieses Mutexes warten
			\item \texttt{try\_lock} -- versucht, den Besitz sofort zu erhalten (falls kein aktueller Besitzer)
			\item \texttt{unlock}
		\end{itemize}
	\end{block}
	
	\pause
	
	\alert{Häufiges Problem: \texttt{unlock} vergessen}
	\begin{block}{std locks}
		\begin{itemize}
			\item RAII: Wie smart ptr, nur eben für locking
			\item Im ctor \texttt{lock}, im dtor \texttt{unlock}
			\item Wichtigster Vertreter: \texttt{std::unique\_lock}
		\end{itemize}
	\end{block}
\end{frame}

\begin{frame}[fragile]{ Beispiel: \texttt{mutex} + \texttt{unique\_lock} }
	\begin{lstlisting}
		#include <mutex>
		LargeData dat;
		mutex dat_mutex;
		
		void calc(int p)
		{
			/* ... */
			{unique_lock datLock( dat_mutex );
				dat.change();
			}
			/* ... */
		}
	\end{lstlisting}
\end{frame}

\begin{frame}[fragile]{ Viele tote Katzen: dead-lock }
	\alert{Viele Katzen sterben bei einem dead-lock!}
	
	\begin{lstlisting}[basicstyle=\scriptsize]
		AdditionalData addDat;
		mutex addDat_mutex;
		
		void calc0(int p)
		{
			/* ... */
			{unique_lock addDatLock = {addDat_mutex};
			 unique_lock    datLock = {dat_mutex};
				dat.change();
			}
		}
		
		void calc1(int p)
		{
			/* ... */
			{unique_lock    datLock = {dat_mutex};
			 unique_lock addDatLock = {addDat_mutex};
				dat.change();
			}
		}
	\end{lstlisting}
\end{frame}


\subsection{Einstieg in elegantere concurrency}

\begin{frame}{Einstieg in elegantere concurrency: \texttt{async}}
	Ein Traum wie aus einer Script-Sprache:
	\begin{block}{ \texttt{std::async} }
		\begin{itemize}
			\item \texttt{async} ist eine Funktion, Parameter wie beim ctor von \texttt{thread}
			\item führ die angegebene Funktion aus, wobei die Implementierung/OS entscheidet, ob \emph{sofort} in einem neuen Thread oder \emph{später} (lazy evaluation)
			\item kann gezwungen werden per Parameter, einen neuen Thread zu starten oder auch nicht (lazy evaluation)
			\item Rückgabetyp: ein \texttt{future}
		\end{itemize}
	\end{block}
\end{frame}

\begin{frame}{Einstieg in elegantere concurrency: promises \& futures}
	Hier nur als Skizze!
	
	\begin{block}{promises \& futures}
		aktueller Thread = $A$, neuer Thread für Aufgabe = $N$
		\begin{itemize}
			\item $A$ erhält beim/vor dem Erzeugen von $N$ eine \texttt{future}
			\item \texttt{future} \enquote{kennt} intern $N$ und die \texttt{promise}
			\item \texttt{promise} verspricht, einen Rückgabewert zu enthalten
			\item<2-> $N$ speichert sein Ergebnis in der \texttt{promise}
			\item<3-> $A$ kann auf die \texttt{future} warten und wenn der Rückgabewert gesetzt wurde, diesen auslesen
			\item<3-> ODER, bei lazy evaluation: statt das $A$ wartet, wird (erst jetzt!) in $A$ der Rückgabewert berechnet
			\item<4-> Beim Auslesen dieses Rückgabewertes kann eine Exception von $N$ nach $A$ propagiert werden!
		\end{itemize}
	\end{block}
\end{frame}

\begin{frame}[fragile]{ Beispiel: \texttt{async} \& \texttt{future} }
	\begin{lstlisting}
		int calcHard(int i, double d)
		{
			int result;
			/* work hard, maybe throw up */
			return result;
		}
		
		
		#include <future>
		
		future < int > future_result = async(&calcHard, 42, 21.0);
		/* do something or not */
		int result = future_result.get();
	\end{lstlisting}
\end{frame}
